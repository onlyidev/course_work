# S3QR

- Survey

  - The authors seem to have come up with ways to preserve functionality, reduce inefficiency, increase stealth

  - The authors also mention the importance of keeping the malware size small, otherwise it might get flagged as an anomaly

- Question

  - Are PE-invalid cases addressed?

    - No

  - How is efficiency increased?

    - By taking the modifications (perturbations) from known benign samples

  - How is iterative transformation process addressed?

    - It is not. The process is still iterative, however, by using the benign samples it should converge much quicker

  - How is the program size kept small?

    - With a penalty term directly proportional to the size of the program

* * *

# Meta Info

**Research Question:** How can we make adversarial attacks query-efficient and functionality-preserving without impacting their ability to evade malware detectors in black-box scenarios?

**Context:** Black-box models are popular and considered in this paper. This paper addresses complications of

- Altering the program in feature space

- Running the program in a sandbox (many malware can detect that they’re being run in a virtual environment)

- Not considering the file size and other trivial metrics

- Applying transformations and querying the detector iteratively

* * *

# Notes

Malware detectors used in this paper are both theoretical and something we’ve read about before:

- MalConv

- GBDT (Gradient Boosting Decision Trees)

The authors introduce a black-box adversarial attack framework GAMMA (Genetic Adversarial Machine learning Malware Attack)

The query-inefficiency is addressed by considering samples that definitely facilitate evasion (are taken from benign samples) rather than being generated at random.

The stealth aspect is ensured formally by treating the attack as a constrained optimization problem by adding a penalty term directly proportional to the size.

A few hypyerparameters:

- $\lambda$ - weight of size penalty

- $T$ - query budget

Since the method promotes sparse solutions, this means that only a few section will be changed with benign samples.

In hard-label cases (model does not provide a real-valued output), random transformations will be tried until an evasive variant is found. Only then the size minimization will begin.

## Functionality preserving manipulations

Can be:

- Structural

- Behavioral

### PE structural manipulations

- Perturb header fields

- Fill slack space

- Padding

- Manipulate DOS header and Stub

- Extend DOS header

- Content shifting

- Import function injection

- Section injection

### PE behavioral manipulations

- Packing (encrypt or encode)

- Direct (rewrite code to equivalent instructions)

- Minimal invasive (new entry-point that immediately gives control to the old entry-point)

- Full translation (decompile, perturb, recompile)

- Dropper (full program is put inside another program that start this one at run time)

## Experiments

GAMMA works well even in black-box scenarios due to the injection content - the benignware samples.

From the time complexity viewpoint, GAMMA spends the most time querying the detector.

The authors found that using packing immediately increases the chances of the program being classified as malware even if it is goodware.

As a potential defense strategy, the authors suggest adversarial re-training, however, they have not tested this.

This paper does not consider dynamic classifiers, as those would easily detect the modified malware.

# Ideas

- Adversarial retraining could be researched in Bsc
