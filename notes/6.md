# S3QR

- Survey - the authors seem convinced that AI-based malware detectors, while useful at adapting to the rapidly growing sample space of malware, are quite vulnerable to poisoning and evasion attacks. They construct a framework - DQEAF, that is able to demonstrate these weaknesses by utilizing reinforcement learning and is extensible to a variety of platforms.

- Question

  - How exactly are raw byte streams converted to a 513-dimensional feature vector?

    - The authors do not fully cover this part. They mention counting the byte histogram normalized to sum to unity, 2D entropy histogram. Apart from that, no further details of implementation are specified.

  - What are the evasive actions?

    - ARBE

    - ARI

    - ARS

    - RS

  - How does the architecture of the framework differ from MalGAN or MalFox?

    - Conceptually, these frameworks are quite similar. They generate an adversarial example, check it’s evasiveness based on some sort of environment and adjust the generation parameters based on the output of the environment.

    - Technologically, MalGAN and MalFox use Generative Adversarial Networks for training, while DQEAF uses reinforcement learning with Q-networks for the agent. GAN approach seems to be more effective based on the results

    - MalFox is the most advanced out of the 3, as it uses more sophisticated perturbations, such as changing the control flow and encrypting the malware

    - DQEAF explores longer action sequences than MalGAN or MalFox

  - Are unsupervised learning based malware detectors also vulnerable to adversarial examples generated by DQEAF?

    - The authors do not cover this topic. They only explore supervised-learning based malware detectors

* * *

# Meta Info

**Research Question:** What are the weaknesses of AI-based malware detectors?

**Context:** The vulnerabilities in ML-based malware detectors have been noticed by researchers. Evasion or poisoning research has advanced, MalGAN paper has already been published. Other papers considering deep reinforcement learning in the same context have already been published,

Authors improve upon:

- Each action (perturbation) is guaranteed to not corrupt the malware

- Low dimensionality of feature vectors (d-513) to reduce instability

- Priority consideration when replaying past transitions

* * *

# Notes

white-box attack

- The attacker has full knowledge of what AI model is used, how it is trained and how it classifies malware

- The attacker knows the model's parameters

black-box attack

- The attacker does not know the algorithms and parameters used by malware classifiers

- The attacker is able to interact with the detector and receive boolean labels

The intelligent learning of the framework comes from MDP (Markov Decision Process). Under Markov hypothesis there exists a series of transitions to an end state.

Reinforcement learning with extremely large action space would take a lot of time and would increase the difficulty of training. Therefore, the authors chose only 4 actions.

The actions (they should be simple and never fail):

- ARBE (Append Random Bytes at the End)

- ARI (Append Random library with a random function name to the Import address table)

- ARS (Append a Random Section) - the section space consists of 7 sections

- RS (Remove Signature from certificate table of the DataDirectory)

The reward for the agent is generated based on the detectors result (0 if “malicious”, inversely proportional to the turn count otherwise)

Since the environment is multivariable and might not give the same reward for the same actions, a discount factor is added that reflects this future uncertainty

DQEAF agent uses deep Q-networks (extension of CNNs)

DQEAF is inspired by prioritized experience replay, since only successful modifications of malware can get high reward, they should have higher replay priority.

The environment is prepared using the *gym toolset* provided by OpenAI.

Malware samples used in experiments come from VirusTotal

The authors seem to suggest that 4 separate agents were trained for 4 types of malware families. This choice is not explained further.

The evasion rates do not seem all that stable. They range from 17.5% for trojan family up to 75% for backdoor family. The authors also perform cross-validation, but still do not explain why the agent model is not generalized to all families.
