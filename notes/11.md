# S3QR

- Survey

  - The authors are suggesting a new method to generate unseen malware form existing malware

  - The generated AEs should be different from the original by generating unused code branches (caves), which would preserve functionality.

  - The new malware could be used to train detectors to increase their robustness

- Question

  - Describe the learning process

    - Stage 1: insert code caves with random bytes

    - Stage 2: optimize the content using genetic algorithms

    - Repeat until evaded or stop condition reached

  - How do dynamic detectors react to such changes?

    - They should not. the inserted sections are not used (not even loaded into memory)

  - Feature vectors?

    - the concatenated array of the code caves is the chromosome

  - Ensure valid AE execution?

    - No sandbox was used. There might be a risk of samples being PE-invalid (as described in #8)

* * *

# Meta Info

**Research Question:** How might we generate new malware from existing ones in order to increase current ML-based detectors' robustness?

**Context:**

- It is known that modifying a compiled binary can lead to corruption

- It is known that ML detectors can use static, dynamic or a combination of both analysis strategies

- Code caves are described as padding bytes in PE binaries (not used bytes that are usually there due to alignment)

- Code caves have been used to trojanize legitimate applications, however, it is worth nothing, that code caves are very limited in size

- The authors think that finding for each code cave

  - the smallest size needed

  - the right location

  - the adequate content  
        is an optimization problem that can be solved in a reasonable amount of time

* * *

# Notes

The authors make their code public in [https://github.com/JavierYuste/Optimization-of-code-caves-in-malware-binaries-to-evade-Machine-Learning-detectors](https://github.com/JavierYuste/Optimization-of-code-caves-in-malware-binaries-to-evade-Machine-Learning-detectors)

The proposed method for generating perturbations is based on introducing additional bytes that can be freely manipulated. The authors need an exploratory systematic method for that.

The authors chose to analyze the black-box scenario. For a surrogate detector, they chose MalConv, which operates on raw bytes of the samples.

The amount of space used in memory by any program must be a multiple of the OS page size. This is where the unused spaces come from.

In PE, the headers specify the start of each code section. This may be exploited to generate some “free space” that will never be loaded into memory.

Metaheuristics are high-level procedures which help subordinate heuristics escape the local minima and thus allowing for very quick optimization. A class of metaheuristics are evolutionary algorithms and genetic algorithms are a subclass of those. GAs consist of 3 main steps:

- selection (select based on quality and diversity)

- crossover (construct new solutions based on the characteristics of existing ones)

- mutation (randomly modify parts of solutions)

A solution for the GA is represented as **all newly introduced unused code spaces concatenated into a single array**.

Chromosomes here are represented by the entire solution  
Genes are each byte of the solution

Selection:

- elitist group (top quality)

- diverse group (randomized tournaments, pick best from each group)

Crossover:

- random voting (each gene has an equal probability to be selected from either of the parents)

- weighted voting (probability distribution for each gene to be selected is based on quality of the parents)

Mutation:

- experimental probabilities $p_1$ and $p_2$ describe the probability for solution mutation and percentage of the genes to be mutated respectively

Aggressive selection mechanisms (elitist group, best solution for next iteration) may speed up convergence, but at a cost of falling into local optima regions. Experimental mutation probabilities should be selected accordingly to lower the convergence rate.

dataset: 3540 PE execs (out of 42658 total files)

The authors noted that the selection of p1 and p2 has implications towards convergence rate, however, there is no experiment for that and the selection of parameters followed different criteria. *(****Idea*** *if replicated - draw convergence graphs depending on p1 and p2)*

The authors found that the location of code caves is not very important. They do mention, that this may be because of the characteristic of the detector’s model (e.g. MalConv uses CNNs, which are supposed to find features regardless of their location).

The authors' proposed method of perturbation outperforms the competition. However, it takes considerably longer for them to do so.

The proposed method decreased the average detection rate for commercial detectors (statistically significantly), however, it performed about as well as the competitors.

In the case of adversarial retraining (using the newly generated AEs to improve the detector network), the increase in detections was very substantial and further AE generation was much more difficult. This means that certain ML detectors would be able to benefit retraining on samples produced by the suggested methods.
