# S3QR

- Survey

  - The authors are targeting Intrusion Detection Systems - these are systems that look at real time data (e.g. network traffic) and determine whether it is safe or not. The authors seem to have come up with an attack framework that is able to generate adversarial network traffic examples, that could inform the attackers about what traffic would avoid detection

- Question

  - Can existing traffic be altered automatically?

    - It might. Authors suggest that they could create obfuscated network traffic based on the adversarial examples generated here.

  - Has this been tested on real IDS systems?

    - No, only Academia models

  - How is functionality preservation ensured?

    - By modifying only non-functional features

* * *

# Meta Info

**Research Question:** How might we bypass network intrusion detection systems?

**Context:** Paper released in 2022, GANs are quite popular. Other papers related to adversarial examples and malware talk about static code analysis. This, however, introduces a use case for GANs where dynamic features (network traffic) are altered to obfuscate malware.

* * *

# Notes

NSL-KDD was used as the benchmark dataset. This dataset is extracted from real network environment. It includes normal traffic and malicious traffic:

- Probing (Probe)

- Denial of Service (DoS)

- User to Root (U2R)

- Root to Local (R2L)

The features of IDSGAN consist of 9 discrete values and 32 continuous values. They can be categorized into 4 sets:

- intrinsic

- content

- time-based traffic

- host-based traffic

> To prevent the non-convergence and instability of GAN, IDSGAN is proposed based on Wasserstein GAN [1].

To preserve malicious functionality, the IDSGAN only alters the non-functional features of the malware (table of which features are functional is provided in the paper)

IDSGAN IN: Original malicious and normal network traffic records  
IDSGAN OUT: Modified traffic records

IDSGANs assumes that the black-box model can be queried to obtain the classification results.

IDSGAN uses various pre-trained Academia ML models as black-box classifiers (not ideal).

Since non-functional features for each NSL-KDD category (normal + 4 malicious) are different, IDSGAN generates adversarial examples for solely one attack category each time.

The IDSGAN framework performs well when modifying as many features as it is allowed by the restriction mechanism, and when it is limited even more to modify less and less features (with a slight decrease of evasion rate). This shows that IDSGAN is robust and adaptive.

The authors propose that in future work they could use the adversarial examples generated by IDSGAN to generate obfuscated network traffic.
