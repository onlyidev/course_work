
@article{zhongReinforcementLearningBased2022,
	title = {Reinforcement learning based adversarial malware example generation against black-box detectors},
	volume = {121},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404822002632},
	doi = {10.1016/j.cose.2022.102869},
	abstract = {Recent advances in machine learning offer attractive tools for sophisticated adversaries. An attacker could transform malware into its adversarial version but retain its malicious functionality by employing a dedicated perturbation method. These adversarial malware examples have demonstrated the effectiveness to bypass antivirus engines. However, recent works only leverage a single perturbation method to generate adversarial examples, which cannot defeat advanced detectors. In this paper, we propose a reinforcement learning-based framework called {MalInfo}, which could generate powerful adversarial malware examples to evade the third-party detectors via an adaptive selection of a perturbation path for each malware in our collected dataset with 1000 diverse malware. To cope with limited computation, {MalInfo} applies either dynamic programming or temporal difference learning to choose the optimal perturbation path where each path is formed by the combination of Obfusmal, Stealmal, and Hollowmal. We provide a proof-of-concept implementation and extensive evaluation of our framework. Both the detection rate and evasive rate have substantially been improved compared with the state-of-art research {MalFox} Zhong etÂ al. (2021). To be specific, The average detection rates for dynamic programming and temporal difference learning are 23.2\% (21.9\% lower than {MalFox}) and 27.5\% (7.4\% lower than {MalFox}), respectively, and the average evasive rates are 65.8\% (17.1\% higher than {MalFox}) and 59.4\% (5.7\% higher than {MalFox}), respectively.},
	pages = {102869},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Zhong, Fangtian and Hu, Pengfei and Zhang, Guoming and Li, Hong and Cheng, Xiuzhen},
	urldate = {2024-09-14},
	date = {2022-10-01},
	keywords = {Adversarial malware examples, Dynamic programming, Malware, Reinforcement learning, Temporal difference learning, \#3},
	file = {ScienceDirect Snapshot:C\:\\Users\\liuda\\Zotero\\storage\\S3H8ZSE4\\S0167404822002632.html:text/html},
}

@inproceedings{kawaiImprovedMalGANAvoiding2019,
	title = {Improved {MalGAN}: Avoiding Malware Detector by Leaning Cleanware Features},
	url = {https://ieeexplore.ieee.org/abstract/document/8669079},
	doi = {10.1109/ICAIIC.2019.8669079},
	shorttitle = {Improved {MalGAN}},
	abstract = {In recent years, researches on malware detection using machine learning have been attracting wide attention. At the same time, how to avoid these detections is also regarded as an emerging topic. In this paper, we focus on the avoidance of malware detection based on Generative Adversarial Network ({GAN}). Previous {GAN}-based researches use the same feature quantities for learning malware detection. Moreover, existing learning algorithms use multiple malware, which affects the performance of avoidance and is not realistic on attackers. To settle this issue, we apply differentiated learning methods with the different feature quantities and only one malware. Experimental results show that our method can achieve better performance than existing ones.},
	eventtitle = {2019 International Conference on Artificial Intelligence in Information and Communication ({ICAIIC})},
	pages = {040--045},
	booktitle = {2019 International Conference on Artificial Intelligence in Information and Communication ({ICAIIC})},
	author = {Kawai, Masataka and Ota, Kaoru and Dong, Mianxing},
	urldate = {2024-09-14},
	date = {2019-02},
	keywords = {Malware, adversarial machine learning, deep learning, Detectors, Feature extraction, Gallium nitride, {GAN}, Generators, malware detection, Radio frequency, Training data, \#4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\liuda\\Zotero\\storage\\48JT6ER7\\8669079.html:text/html},
}

@article{zhongMalFoxCamouflagedAdversarial2024,
	title = {{MalFox}: Camouflaged Adversarial Malware Example Generation Based on Conv-{GANs} Against Black-Box Detectors},
	volume = {73},
	issn = {1557-9956},
	url = {https://ieeexplore.ieee.org/abstract/document/10017127?casa_token=tILgWcHIR8cAAAAA:lqMBa9dcRq7juZAQV_fBQij4ZQYyD5NaBbYLfnzrfnbcr_j64SHELMdyIoHmO-F6nsRgZtU},
	doi = {10.1109/TC.2023.3236901},
	shorttitle = {{MalFox}},
	abstract = {Deep learning is a thriving field currently stuffed with many practical applications and active research topics. It allows computers to learn from experience and to understand the world in terms of a hierarchy of concepts, with each being defined through its relations to simpler concepts. Relying on the strong capabilities of deep learning, we propose a convolutional generative adversarial network-based (Conv-{GAN}) framework titled {MalFox}, targeting adversarial malware example generation against third-party black-box malware detectors. Motivated by the rival game between malware authors and malware detectors, {MalFox} adopts a confrontational approach to produce perturbation paths, with each formed by up to three methods (namely Obfusmal, Stealmal, and Hollowmal) to generate adversarial malware examples. To demonstrate the effectiveness of {MalFox}, we collect a large dataset consisting of both malware and benignware programs, and investigate the performance of {MalFox} in terms of accuracy, detection rate, and evasive rate of the generated adversarial malware examples. Our evaluation indicates that the accuracy can be as high as 99.0\% which significantly outperforms the other 12 well-known learning models. Furthermore, the detection rate is dramatically decreased by 56.8\% on average, and the average evasive rate is noticeably improved by up to 56.2\%.},
	pages = {980--993},
	number = {4},
	journaltitle = {{IEEE} Transactions on Computers},
	author = {Zhong, Fangtian and Cheng, Xiuzhen and Yu, Dongxiao and Gong, Bei and Song, Shuaiwen and Yu, Jiguo},
	urldate = {2024-09-15},
	date = {2024-04},
	note = {Conference Name: {IEEE} Transactions on Computers},
	keywords = {Adversarial malware examples, Malware, deep learning, Detectors, Closed box, Computer viruses, Electronic mail, Engines, generative adversarial network, malware, Perturbation methods, \#2},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\liuda\\Zotero\\storage\\7PV5GAG2\\10017127.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\liuda\\Zotero\\storage\\3UTSNQ46\\Zhong et al. - 2024 - MalFox Camouflaged Adversarial Malware Example Generation Based on Conv-GANs Against Black-Box Dete.pdf:application/pdf},
}

@article{nguyenGenerativeAdversarialNetworks2023,
	title = {Generative adversarial networks and image-based malware classification},
	volume = {19},
	issn = {2263-8733},
	url = {https://doi.org/10.1007/s11416-023-00465-2},
	doi = {10.1007/s11416-023-00465-2},
	abstract = {For efficient malware removal, determination of malware threat levels, and damage estimation, malware family classification plays a critical role. In this paper, we extract features from malware executable files and represent them as images using various approaches. We then focus on generative adversarial networks ({GAN}) for multiclass classification and compare our {GAN} results to other popular machine learning techniques, including support vector machine ({SVM}), {XGBoost}, and restricted Boltzmann machines ({RBM}). We find that the {AC}-{GAN} discriminator is generally competitive with other machine learning techniques. We also evaluate the utility of the {GAN} generative model for adversarial attacks on image-based malware detection. While {AC}-{GAN} generated images are visually impressive, we find that they are easily distinguished from real malware images using any of several learning techniques. This result indicates that our {GAN} generated images are of surprisingly little value in adversarial attacks.},
	pages = {579--595},
	number = {4},
	journaltitle = {Journal of Computer Virology and Hacking Techniques},
	shortjournal = {J Comput Virol Hack Tech},
	author = {Nguyen, Huy and Di Troia, Fabio and Ishigaki, Genya and Stamp, Mark},
	urldate = {2024-09-15},
	date = {2023-11-01},
	langid = {english},
	keywords = {\#1, Artificial Intelligence},
	file = {Full Text PDF:C\:\\Users\\liuda\\Zotero\\storage\\ADKB6C5V\\Nguyen et al. - 2023 - Generative adversarial networks and image-based malware classification.pdf:application/pdf},
}
